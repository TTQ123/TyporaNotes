# 图解系统

## 1.CPU如何执行程序

**如何让程序跑的更快**

程序执行的时候，耗费的 CPU 时间少就说明程序是快的，对于程序的 CPU 执行时间，我们可以拆解成 **CPU 时钟周期数（\*CPU Cycles\*）和时钟周期时间（\*Clock Cycle Time\*）的乘积**。

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E7%A8%8B%E5%BA%8F%E6%89%A7%E8%A1%8C/%E7%A8%8B%E5%BA%8F%E7%9A%84CPU%E6%89%A7%E8%A1%8C%E6%97%B6%E9%97%B4%E5%85%AC%E5%BC%8F1.png)

![uTools_1679918870932](https://ttqblogimg.oss-cn-beijing.aliyuncs.com/uTools_1679918870932.png)

**我们程序员无法决定时钟周期时间，只能从CPU时钟周期数入手**

**1.用更少的指令去执行程序**

**2.尽量少去执行一些非常费时间的指令(例如斐波那契数列用递归的方法就很慢)**

**不同位数的计算机**

**64位就是8字节**

```bash
1.多少位的计算机就陪多少位的线路位宽
2.64位计算机能运算超过32位的数
3.64位计算机的寻址能力更强
4.64位计算机的指令是64位，32位计算机的指令是32位
5.32位指令可以在64位指令上运行，64位很困难
6.64 位操作系统，指令也就是 64 位，因此不能装在 32 位机器上。
7.总之，硬件的 64 位和 32 位指的是 CPU 的位宽，软件的 64 位和 32 位指的是指令的位宽。
```



## 2.磁盘和内存

**存储器包括：**

![uTools_1679919532952](https://ttqblogimg.oss-cn-beijing.aliyuncs.com/uTools_1679919532952.png)

![uTools_1679919597887](https://ttqblogimg.oss-cn-beijing.aliyuncs.com/uTools_1679919597887.png)

所以，存储层次结构也形成了**缓存**的体系。

不同的存储器之间性能差距很大，构造存储器分级很有意义，分级的目的是要构造**缓存**体系

**总结：**

```bash
1.寄存器:正在处理的数据(速度最快容量最小)
2.CPU 中的 L1-L3 Cache(静态随机存储器,不断电就存在):L1和L2相当于短期记忆，L3相当于长期记忆
3.内存(动态缓存，需要不断电并且不断刷新保存)：就是电脑的运行内存几GB  长期记忆
4.SSD/HDD 硬盘(不通电也不会消失):相当于整个大脑
5.硬盘作为内存的缓存，内存作为CPU cache作为的缓存
```

## 3.如何写出让CPU跑的更快的代码

![uTools_1679920031645](https://ttqblogimg.oss-cn-beijing.aliyuncs.com/uTools_1679920031645.png)

CPU 怎么知道要访问的内存数据，是否在 Cache 里？如果在的话，如何找到 Cache 对应的数据呢：通过各种映射手段(在小区域存储大区域的数据)

对于直接映射 Cache 采用的策略，就是把内存块的地址始终「映射」在一个 CPU Cache Line（缓存块） 的地址，至于映射关系实现方式，则是使用「取模运算」，取模运算的结果就是内存块地址对应的 CPU Cache Line（缓存块） 的地址。

![uTools_1679920196198](https://ttqblogimg.oss-cn-beijing.aliyuncs.com/uTools_1679920196198.png)

为了区别不同的内存块，在对应的 CPU Cache Line 中我们还会存储一个**组标记（Tag）**。这个组标记会记录当前 CPU Cache Line 中存储的数据对应的内存块，我们可以用这个组标记来区分不同的内存块。

除了组标记信息外，CPU Cache Line 还有两个信息：

- 一个是，从内存加载过来的实际存放**数据（\*Data\*）**。
- 另一个是，**有效位（\*Valid bit\*）**，它是用来标记对应的 CPU Cache Line 中的数据是否是有效的，如果有效位是 0，无论 CPU Cache Line 中是否有数据，CPU 都会直接访问内存，重新加载数据。

CPU 在从 CPU Cache 读取数据的时候，并不是读取 CPU Cache Line 中的整个数据块，而是读取 CPU 所需要的一个数据片段，这样的数据统称为一个**字（\*Word\*）**。那怎么在对应的 CPU Cache Line 中数据块中找到所需的字呢？答案是，需要一个**偏移量（Offset）**。

因此，一个内存的访问地址，包括**组标记(哪一组)、CPU Cache Line 索引(对应哪个)、偏移量(这一组的哪个字)**这三种信息，于是 CPU 就能通过这些信息，在 CPU Cache 中找到缓存的数据。

而对于 CPU Cache 里的数据结构，则是由**索引(CPU Cache Line 的地址) + 有效位（数据是否有效） + 组标记(哪一组) + 数据块(映射的是哪一块数据)**组成。

**如果内存中的数据已经在 CPU Cache 中了，那 CPU 访问一个内存地址的时候，会经历这 4 个步骤：**

1. 根据内存地址中索引信息，计算在 CPU Cache 中的索引，也就是找出对应的 CPU Cache Line 的地址；
2. 找到对应 CPU Cache Line 后，判断 CPU Cache Line 中的有效位，确认 CPU Cache Line 中数据是否是有效的，如果是无效的，CPU 就会直接访问内存，并重新加载数据，如果数据有效，则往下执行；
3. 对比内存地址中组标记和 CPU Cache Line 中的组标记，确认 CPU Cache Line 中的数据是我们要访问的内存数据，如果不是的话，CPU 就会直接访问内存，并重新加载数据，如果是的话，则往下执行；
4. 根据内存地址中偏移量信息，从 CPU Cache Line 的数据块中，读取对应的字。



❤**重点**

###  如何写出让 CPU 跑得更快的代码？

- **对于数据缓存，我们在遍历数据的时候，应该按照内存布局的顺序操作，这是因为 CPU Cache 是根据 CPU Cache Line 批量操作数据的，所以顺序地操作连续内存数据时，性能能得到有效的提升；**
- **对于指令缓存，有规律的条件分支语句能够让 CPU 的分支预测器发挥作用，进一步提高执行的效率；**
- **对于多核 CPU 系统，线程可能在不同 CPU 核心来回切换，这样各个核心的缓存命中率就会受到影响，于是要想提高线程的缓存命中率，可以考虑把线程绑定 CPU 到某一个 CPU 核心。**

例子

![uTools_1679920625786](https://ttqblogimg.oss-cn-beijing.aliyuncs.com/uTools_1679920625786.png)

**形式一是连续访问数组的 速度更快**

![uTools_1679920672805](https://ttqblogimg.oss-cn-beijing.aliyuncs.com/uTools_1679920672805.png)

**给出了有规律的条件分支语句**